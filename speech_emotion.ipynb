{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 16.0 MB/s eta 0:00:00\n",
      "Collecting transformers==4.26.1\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-win_amd64.whl (269 kB)\n",
      "     -------------------------------------- 269.5/269.5 KB 8.4 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 20.1 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "     ------------------------------------- 330.1/330.1 KB 10.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from transformers==4.26.1) (23.2)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.3/78.3 KB 2.2 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-win_amd64.whl (152 kB)\n",
      "     -------------------------------------- 152.8/152.8 KB 4.6 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.6/62.6 KB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.26.1) (4.9.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "     -------------------------------------- 170.9/170.9 KB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers==4.26.1) (0.4.6)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "     -------------------------------------- 121.1/121.1 KB 3.6 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.6/61.6 KB 3.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp39-cp39-win_amd64.whl (100 kB)\n",
      "     -------------------------------------- 100.4/100.4 KB 6.0 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "     -------------------------------------- 163.8/163.8 KB 9.6 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, urllib3, tqdm, regex, pyyaml, numpy, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, transformers\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.13.1 fsspec-2024.2.0 huggingface-hub-0.20.3 idna-3.6 numpy-1.23.5 pyyaml-6.0.1 regex-2023.12.25 requests-2.31.0 tokenizers-0.13.3 tqdm-4.66.2 transformers-4.26.1 urllib3-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 12.1 MB/s eta 0:00:00\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.4/139.4 KB 8.1 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (1.23.5)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "     -------------------------------------- 103.9/103.9 KB 6.2 MB/s eta 0:00:00\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.7/133.7 KB 2.0 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "     -------------------------------------- 226.7/226.7 KB 2.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard) (1.16.0)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.60.1-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 18.3 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.24.0,>=3.19.6\n",
      "  Downloading protobuf-4.25.3-cp39-cp39-win_amd64.whl (413 kB)\n",
      "     -------------------------------------- 413.4/413.4 KB 8.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard) (58.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipywidgets) (5.14.1)\n",
      "Collecting widgetsnbextension~=4.0.10\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 18.3 MB/s eta 0:00:00\n",
      "Collecting jupyterlab-widgets~=3.0.10\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "     -------------------------------------- 215.0/215.0 KB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: stack-data in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from markdown>=2.6.8->tensorboard) (7.0.1)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.17.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Installing collected packages: widgetsnbextension, tensorboard-data-server, protobuf, MarkupSafe, jupyterlab-widgets, grpcio, absl-py, werkzeug, markdown, tensorboard, ipywidgets\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 grpcio-1.60.1 ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 markdown-3.5.2 protobuf-4.25.3 tensorboard-2.16.2 tensorboard-data-server-0.7.2 werkzeug-3.0.1 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.0-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     -------------------------------------- 345.4/345.4 KB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "     ------------------------------------- 505.5/505.5 KB 16.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.0 pytz-2024.1 tzdata-2024.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.7/536.7 KB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: IPython in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (8.18.1)\n",
      "Collecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "     -------------------------------------- 116.3/116.3 KB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "     -------------------------------------- 166.4/166.4 KB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.20.3)\n",
      "Collecting pyarrow>=12.0.0\n",
      "  Downloading pyarrow-15.0.0-cp39-cp39-win_amd64.whl (24.9 MB)\n",
      "     --------------------------------------- 24.9/24.9 MB 12.6 MB/s eta 0:00:00\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "     -------------------------------------- 133.4/133.4 KB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (23.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-win_amd64.whl (29 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "     ------------------------------------- 366.0/366.0 KB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (2.17.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (5.14.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (0.19.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (4.9.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (3.0.43)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (1.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (5.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from IPython) (0.4.6)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.8/60.8 KB 3.4 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.9/76.9 KB 2.1 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "     ---------------------------------------- 50.7/50.7 KB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->IPython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython) (0.2.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rhear\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->IPython) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->IPython) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->IPython) (2.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rhear\\appdata\\roaming\\python\\python39\\site-packages (from asttokens>=2.1.0->stack-data->IPython) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, attrs, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.2.0\n",
      "    Uninstalling fsspec-2024.2.0:\n",
      "      Successfully uninstalled fsspec-2024.2.0\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.2.0 datasets-2.17.1 dill-0.3.8 frozenlist-1.4.1 fsspec-2023.10.0 multidict-6.0.5 multiprocess-0.70.16 pyarrow-15.0.0 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script datasets-cli.exe is installed in 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\rhear\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U numpy==1.23.5 transformers==4.26.1\n",
    "%pip install tensorboard ipywidgets\n",
    "%pip install pandas\n",
    "%pip install datasets IPython\n",
    "%pip install torch torchaudio evaluate tqdm \n",
    "%pip install soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, random, glob\n",
    "os.environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, Audio, DatasetDict\n",
    "from datasets import Audio, Features, ClassLabel\n",
    "\n",
    "import torch\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"SAD\", \n",
    "          \"ANGRY\",\n",
    "          \"DISGUST\",\n",
    "          \"FEAR\",\n",
    "          \"HAPPY\",\n",
    "          \"NEUTRAL\"]\n",
    "\n",
    "\n",
    "NUM_OF_LABELS = len(labels)\n",
    "\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "initial_label_update = {\"SAD\": \"SAD\", \n",
    "                        \"ANG\": \"ANGRY\",\n",
    "                        \"DIS\": \"DISGUST\",\n",
    "                        \"FEA\": \"FEAR\",\n",
    "                        \"HAP\": \"HAPPY\",\n",
    "                        \"NEU\": \"NEUTRAL\"}\n",
    "\n",
    "\n",
    "print(labels)\n",
    "print(NUM_OF_LABELS)\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"/content/drive/MyDrive/Speech Emotion Recognition/data\"\n",
    "\n",
    "dir_path = os.path.join(parent_dir, \"*.wav\")\n",
    "\n",
    "files_and_name = glob.glob(dir_path)\n",
    "\n",
    "metadata = pd.DataFrame(files_and_name, columns=[\"file_path\"])\n",
    "\n",
    "metadata['file_name'] = metadata['file_path'].apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "metadata['label'] = metadata['file_path'].apply(lambda x: x.split(\"/\")[-1].split(\"_\")[-2])\n",
    "metadata['label'] = metadata['label'].replace(initial_label_update)\n",
    "metadata['label'] = metadata['label'].replace(label2id)\n",
    "\n",
    "metadata = metadata.drop(columns=[\"file_path\"])\n",
    "\n",
    "metadata_file_location = os.path.join(parent_dir, \"metadata.csv\")\n",
    "metadata.to_csv(metadata_file_location, index=False)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = load_dataset(parent_dir)\n",
    "\n",
    "audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = audio_data.cast_column(\"audio\", Audio(sampling_rate=16_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = audio_data.shuffle(seed=42)\n",
    "\n",
    "audio_data_split = audio_data['train'].train_test_split(test_size=0.25)\n",
    "\n",
    "ds = DatasetDict({\n",
    "    'train' : audio_data_split['train'],\n",
    "    'eval' : audio_data_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Dataset\")\n",
    "print(\"Training Dataset Info: \", ds['train'])\n",
    "print(\"First Sample in Training Dataset\", ds['train'][0])\n",
    "print(\"Last Sample in Training Dataset\", ds['train'][-1])\n",
    "print(\"Unique Values in Label/Class: \", sorted(ds['train'].unique(\"label\")))\n",
    "\n",
    "print(\"\\n\\nEvaluation Dataset\")\n",
    "print(\"Evaluation Dataset Info: \", ds['eval'])\n",
    "print(\"First Sample in Evaluation Dataset\", ds['eval'][0])\n",
    "print(\"Last Sample in Evaluation Dataset\", ds['eval'][-1])\n",
    "print(\"Unique Values in Label/Class: \", sorted(ds['eval'].unique(\"label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    from IPython.display import Audio, display\n",
    "    rand_idx = random.randint(0, len(ds[\"train\"])-1)\n",
    "    example = ds[\"train\"][rand_idx]\n",
    "    audio = example[\"audio\"]\n",
    "    \n",
    "    print(f'Label: {id2label[str(example[\"label\"])]}')\n",
    "    print(f'Shape: {audio[\"array\"].shape}, sampling rate: {audio[\"sampling_rate\"]}')\n",
    "    display(Audio(audio[\"array\"], rate=audio[\"sampling_rate\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CKPT = \"facebook/wav2vec2-base\"\n",
    "MODEL_NAME = MODEL_CKPT.split(\"/\")[-1] + \"-Speech_Emotion_Recognition\"\n",
    "\n",
    "NUM_OF_EPOCHS = 10\n",
    "LEARNING_RATE = 3e-5\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "STRATEGY = \"epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = ds[\"train\"].features[\"audio\"].sampling_rate\n",
    "sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    '''\n",
    "    This function prepares the dataset for the transformer\n",
    "    by applying the feature extractor to it (among other \n",
    "    processes).\n",
    "    '''\n",
    "    max_duration = 5.0 # seconds\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(audio_arrays, \n",
    "                               sampling_rate=feature_extractor.sampling_rate, \n",
    "                               max_length=int(feature_extractor.sampling_rate * max_duration),\n",
    "                               truncation=True)\n",
    "    return inputs\n",
    "\n",
    "encoded_audio = ds.map(preprocess_function, remove_columns=\"audio\", batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    '''\n",
    "    This function calculates & returns the following metrics:\n",
    "    - accuracy\n",
    "    - f1 score\n",
    "    - recall\n",
    "    - precision\n",
    "    '''\n",
    "    import evaluate\n",
    "    \n",
    "    accuracy_metric = evaluate.load(\"accuracy\")\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                             axis=1), \n",
    "                                       references=p.label_ids)['accuracy']\n",
    "    \n",
    "    ### ------------------- F1 scores -------------------\n",
    "    \n",
    "    f1_score_metric = evaluate.load(\"f1\")\n",
    "   \n",
    "    weighted_f1_score = f1_score_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                      axis=1), \n",
    "                                                references=p.label_ids, \n",
    "                                                average='weighted')[\"f1\"]\n",
    "    \n",
    "    micro_f1_score = f1_score_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                   axis=1), \n",
    "                                             references=p.label_ids, \n",
    "                                             average='micro')['f1']\n",
    "    \n",
    "    macro_f1_score = f1_score_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                   axis=1), \n",
    "                                             references=p.label_ids, \n",
    "                                             average='macro')[\"f1\"]\n",
    "    \n",
    "    ### ------------------- recall -------------------\n",
    "    \n",
    "    recall_metric = evaluate.load(\"recall\")\n",
    "    \n",
    "    weighted_recall = recall_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                  axis=1), \n",
    "                                            references=p.label_ids, \n",
    "                                            average='weighted')[\"recall\"]\n",
    "    \n",
    "    micro_recall = recall_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                               axis=1), \n",
    "                                         references=p.label_ids, \n",
    "                                         average='micro')[\"recall\"]\n",
    "    \n",
    "    macro_recall = recall_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                               axis=1), \n",
    "                                         references=p.label_ids, \n",
    "                                         average='macro')[\"recall\"]\n",
    "    \n",
    "    ### ------------------- precision -------------------\n",
    "    \n",
    "    precision_metric = evaluate.load(\"precision\")\n",
    "    \n",
    "    weighted_precision = precision_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                        axis=1), \n",
    "                                                  references=p.label_ids, \n",
    "                                                  average='weighted')[\"precision\"]\n",
    "    \n",
    "    micro_precision = precision_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                     axis=1), \n",
    "                                               references=p.label_ids, \n",
    "                                               average='micro')[\"precision\"]\n",
    "    \n",
    "    macro_precision = precision_metric.compute(predictions=np.argmax(p.predictions, \n",
    "                                                                     axis=1), \n",
    "                                               references=p.label_ids, \n",
    "                                               average='macro')[\"precision\"]\n",
    "    \n",
    "    return {\"accuracy\" : accuracy, \n",
    "            \"Weighted F1\" : weighted_f1_score,\n",
    "            \"Micro F1\" : micro_f1_score,\n",
    "            \"Macro F1\" : macro_f1_score,\n",
    "            \"Weighted Recall\" : weighted_recall,\n",
    "            \"Micro Recall\" : micro_recall,\n",
    "            \"Macro Recall\" : macro_recall,\n",
    "            \"Weighted Precision\" : weighted_precision,\n",
    "            \"Micro Precision\" : micro_precision,\n",
    "            \"Macro Precision\" : macro_precision\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForAudioClassification.from_pretrained(MODEL_CKPT, \n",
    "                                                        num_labels=NUM_OF_LABELS, \n",
    "                                                        label2id=label2id,\n",
    "                                                        id2label= id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=MODEL_NAME,\n",
    "    evaluation_strategy=STRATEGY,\n",
    "    num_train_epochs=NUM_OF_EPOCHS,\n",
    "    save_strategy=STRATEGY,\n",
    "    logging_strategy=\"steps\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_ratio=0.10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_first_step=True,\n",
    "    report_to=\"tensorboard\",\n",
    "    hub_private_repo=True,\n",
    "    push_to_hub=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = encoded_audio[\"train\"],\n",
    "    eval_dataset = encoded_audio[\"eval\"],\n",
    "    tokenizer = feature_extractor,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
